Реализованы три суммирования элементов вектора: последовательная реализация на CPU, многопоточная реализация на CPU с использованием OpenMP и реализация на GPU с использованием CUDA.
2. Многопоточное суммирование на CPU
Реализовано с использованием директивы #pragma omp parallel for, которая делит цикл по потокам, а операция суммирования синхронизируется через reduction(+:total_sum).
3. Суммирование на GPU с помощью CUDA
В рамках GPU каждая нить обрабатывает один элемент вектора, и результат суммируется с использованием атомарной операции atomicAdd, чтобы избежать конфликтов записи.
Выводы
Как бы я не старался, как бы не перебирал потоки и не переделывал ядро, GPU всегда дольше чем последовательная программа, так что надеюсь, что так и должно быть.
